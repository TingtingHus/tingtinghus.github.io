<!DOCTYPE html><html lang="zh_hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="怎样评价模型的好坏"><meta name="keywords" content="统计学"><meta name="author" content="Tingting Hu"><meta name="copyright" content="Tingting Hu"><title>怎样评价模型的好坏 | 南华路草堂</title><link rel="shortcut icon" href="/images/avatar.jpg"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '5.3.0'
} </script><meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="南华路草堂" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">1.1.</span> <span class="toc-text">评价指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AESS%EF%BC%8C%E6%AE%8B%E5%B7%AE%E5%B9%B3%E6%96%B9%E5%92%8CRSS"><span class="toc-number">1.1.1.</span> <span class="toc-text">残差SS，残差平方和RSS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%EF%BC%88MSE%EF%BC%89"><span class="toc-number">1.1.2.</span> <span class="toc-text">均方误差（MSE）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE%EF%BC%88RMSE%EF%BC%89"><span class="toc-number">1.1.3.</span> <span class="toc-text">均方根误差（RMSE）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE-MAE%EF%BC%89"><span class="toc-number">1.1.4.</span> <span class="toc-text">平均绝对误差(MAE）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#R-Squared"><span class="toc-number">1.1.5.</span> <span class="toc-text">R Squared</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AIC%E5%92%8CBIC"><span class="toc-number">1.1.6.</span> <span class="toc-text">AIC和BIC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%BE%E8%91%97%E6%80%A7"><span class="toc-number">1.1.7.</span> <span class="toc-text">显著性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">1.1.8.</span> <span class="toc-text">K折交叉验证</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%BD%A2%E8%AF%84%E4%BB%B7"><span class="toc-number">1.2.</span> <span class="toc-text">图形评价</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%BB%E9%A2%84%E6%B5%8B%E5%80%BC%E5%92%8C%E7%9C%9F%E5%AE%9E%E5%80%BC%E5%9B%BE%E5%BD%A2"><span class="toc-number">1.2.1.</span> <span class="toc-text">画预测值和真实值图形</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="toc-number">1.2.2.</span> <span class="toc-text">学习曲线</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">二分类模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">混淆矩阵的基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87-1"><span class="toc-number">2.2.</span> <span class="toc-text">评价指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%87%86%E7%A1%AE%E7%8E%87%EF%BC%88%E5%8D%B3%E6%89%80%E6%9C%89%E5%88%86%E7%B1%BB%E4%B8%AD%E8%A2%AB%E6%AD%A3%E7%A1%AE%E5%88%86%E7%B1%BB%E7%9A%84%E6%AF%94%E4%BE%8B%EF%BC%8C%E4%B9%9F%E7%A7%B0%E8%AF%86%E5%88%AB%E7%8E%87%EF%BC%89"><span class="toc-number">2.2.1.</span> <span class="toc-text">分类准确率（即所有分类中被正确分类的比例，也称识别率）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AC%E5%9B%9E%E7%8E%87-Recall%EF%BC%88%E4%B9%9F%E7%A7%B0%E7%81%B5%E6%95%8F%E7%8E%87%E3%80%81%E7%9C%9F%E6%AD%A3%E4%BE%8B%E8%AF%86%E5%88%AB%E7%8E%87%EF%BC%89"><span class="toc-number">2.2.2.</span> <span class="toc-text">召回率-Recall（也称灵敏率、真正例识别率）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B2%BE%E7%A1%AE%E7%8E%87%EF%BC%9A%E9%A2%84%E6%B5%8B%E4%B8%BA%E7%9C%9F%E7%9A%84%E6%AD%A3%E6%A0%B7%E6%9C%AC%E5%8D%A0%E6%89%80%E6%9C%89%E9%A2%84%E6%B5%8B%E4%B8%BA%E6%AD%A3%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%AF%94%E4%BE%8B%E3%80%82"><span class="toc-number">2.2.3.</span> <span class="toc-text">精确率：预测为真的正样本占所有预测为正样本的比例。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#F1-Score%EF%BC%88F%E5%BA%A6%E9%87%8F%E6%88%96%E8%80%85F%E5%88%86%E6%95%B0%EF%BC%89"><span class="toc-number">2.2.4.</span> <span class="toc-text">F1-Score（F度量或者F分数）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Loss-Function-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.5.</span> <span class="toc-text">Loss Function(损失函数)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%BD%A2%E8%AF%84%E4%BB%B7-1"><span class="toc-number">2.3.</span> <span class="toc-text">图形评价</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-Precision-Recall-%E6%9B%B2%E7%BA%BF"><span class="toc-number">2.3.1.</span> <span class="toc-text">PR(Precision Recall) 曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ROC%E6%9B%B2%E7%BA%BF"><span class="toc-number">2.3.2.</span> <span class="toc-text">ROC曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AUC%E6%8C%87%E6%A0%87"><span class="toc-number">2.3.3.</span> <span class="toc-text">AUC指标</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">3.</span> <span class="toc-text">多分类问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E8%BD%AC%E5%8C%96%E4%B8%BA2vs2%E9%97%AE%E9%A2%98%E6%9D%A5%E8%AF%84%E4%BB%B7"><span class="toc-number">3.1.</span> <span class="toc-text">多分类转化为2vs2问题来评价</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">3.2.</span> <span class="toc-text">多分类评价指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kappa%E7%B3%BB%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">Kappa系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%B7%E6%98%8E%E8%B7%9D%E7%A6%BB"><span class="toc-number">3.2.2.</span> <span class="toc-text">海明距离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%B0%E5%8D%A1%E5%BE%B7%E7%9B%B8%E4%BC%BC%E7%B3%BB%E6%95%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">杰卡德相似系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%93%B0%E9%93%BE%E6%8D%9F%E5%A4%B1"><span class="toc-number">3.2.4.</span> <span class="toc-text">铰链损失</span></a></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/images/avatar.ico"></div><div class="author-info__name text-center">Tingting Hu</div><div class="author-info__description text-center">一天很长，十年很短</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">19</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">16</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">5</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/images/top.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">南华路草堂</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">怎样评价模型的好坏</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-01-27</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/">方法总结</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">2.8k</span><span class="post-meta__separator">|</span><span>Reading time: 8 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><strong><em>本文是机器学习模型评价指标的整理笔记，主要参考来源有<br>1.机器学习分类器模型评价指标 <a target="_blank" rel="noopener" href="https://blog.csdn.net/login_sonata/article/details/54288653">https://blog.csdn.net/login_sonata/article/details/54288653</a><br>2.机器学习分类模型评价指标详述 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43405406">https://zhuanlan.zhihu.com/p/43405406</a></em></strong></p>
<h1 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h1><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="残差SS，残差平方和RSS"><a href="#残差SS，残差平方和RSS" class="headerlink" title="残差SS，残差平方和RSS"></a>残差SS，残差平方和RSS</h3><p>残差SS是实际观测值和模型估计值之差，残差越大，预测效果越不好<br>实际应用中多使用残差平方和RSS，残差平方和越小，模型拟合效果越好。**<em>较常用**</em></p>
<h3 id="均方误差（MSE）"><a href="#均方误差（MSE）" class="headerlink" title="均方误差（MSE）"></a>均方误差（MSE）</h3><p>MSE （Mean Squared Error）叫做均方误差，用（ 真实值-预测值 ）然后平方之后求和平均，也就是线性回归的损失函数，在线性回归的时候我们的目的就是让这个损失函数最小。</p>
<h3 id="均方根误差（RMSE）"><a href="#均方根误差（RMSE）" class="headerlink" title="均方根误差（RMSE）"></a>均方根误差（RMSE）</h3><p>即MSE开个根号么，其实实质是一样的，只不过用于数据更好的描述。<br>例如：要做房价预测，每平方是万元（真贵），我们预测结果也是万元。那么差值的平方单位应该是 千万级别的，因此最好就开个根号，我们误差的结果就跟我们数据是一个级别的了。</p>
<h3 id="平均绝对误差-MAE）"><a href="#平均绝对误差-MAE）" class="headerlink" title="平均绝对误差(MAE）"></a>平均绝对误差(MAE）</h3><p>MAE用来衡量预测值与真实值之间的平均绝对误差，MAE越小表示模型越好</p>
<h3 id="R-Squared"><a href="#R-Squared" class="headerlink" title="R Squared"></a>R Squared</h3><p>1 -（均方误差MSE/方差），R Squared已进行了归一化，更容易看出模型间的差距。**<em>是最常用的评价指标**</em></p>
<p>分子均方误差MS:就是我们训练出的模型预测的所有误差。【（ 真实值-预测值 ）然后平方之后求和平均】<br>分母方差:就是不管什么我们猜的结果就是y的平均数。（瞎猜的误差）</p>
<p>如果结果是0，就说明我们的模型跟瞎猜差不多；<br>如果结果是1，就说明我们模型无错误；<br>如果结果是0-1之间的数，就是我们模型的好坏程度；<br>如果结果是负数，说明我们的模型还不如瞎猜。（其实导致这种情况说明我们的数据其实没有啥线性关系）</p>
<h3 id="AIC和BIC"><a href="#AIC和BIC" class="headerlink" title="AIC和BIC"></a>AIC和BIC</h3><h3 id="显著性"><a href="#显著性" class="headerlink" title="显著性"></a>显著性</h3><p>可以利用假设检验判断系数是否显著，系数如果都不显著，说明模型不好。**<em>通常用于已知模型，判断因变量与自变量的相关性**</em></p>
<h3 id="K折交叉验证"><a href="#K折交叉验证" class="headerlink" title="K折交叉验证"></a>K折交叉验证</h3><p>这种方法将数据分成K个部分，把其中一格部分用作测试集，其余部分用作训练集以拟合模型。模型拟合好之后，使用测试集进行测试，并计算误差。不断重复这个过程，直到K个部分都测试过。模型最终的误差是所有模型的平均值。**<em>不太常用**</em></p>
<h2 id="图形评价"><a href="#图形评价" class="headerlink" title="图形评价"></a>图形评价</h2><h3 id="画预测值和真实值图形"><a href="#画预测值和真实值图形" class="headerlink" title="画预测值和真实值图形"></a>画预测值和真实值图形</h3><p>最简单直接的方法是画出预测点与真实点的图形，评价预测效果</p>
<h3 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h3><p>学习曲线时，横轴为训练样本的数量，纵轴为准确率。学习曲线就是通过画出不同训练集大小时训练集和交叉验证的准确率，可以看到模型在新数据上的表现，进而来判断模型是否方差偏高或偏差过高，以及增大训练集是否可以减小过拟合。</p>
<p><img src="https://raw.githubusercontent.com/TingtingHus/PicBed/main/image.png" alt="学习曲线.png"></p>
<p>当训练集和测试集的误差收敛但却很高时，为高偏差。<br>左上角的偏差很高，训练集和验证集的准确率都很低，很可能是欠拟合。我们可以增加模型参数，比如，构建更多的特征，减小正则项。 此时通过增加数据量是不起作用的。</p>
<p>当训练集和测试集的误差之间有大的差距时，为高方差。<br>当训练集的准确率比其他独立数据集上的测试结果的准确率要高时，一般都是过拟合。我们可以增大训练集，降低模型复杂度，增大正则项，或者通过特征选择减少特征数。</p>
<p>理想情况是是找到偏差和方差都很小的情况，即收敛且误差较小。（右下）</p>
<h1 id="二分类模型"><a href="#二分类模型" class="headerlink" title="二分类模型"></a>二分类模型</h1><h2 id="混淆矩阵的基本概念"><a href="#混淆矩阵的基本概念" class="headerlink" title="混淆矩阵的基本概念"></a>混淆矩阵的基本概念</h2><p>对于分类模型而言（这里仅以最简单的二分类为例，假设只有0和1两类），最终的判别结果无非就四种情况：实际为0被正确预测为0，实际为0被错误预测为1，实际为1被错误误测为0，实际为1被正确预测为1。<br>以上四类判别结果展示在混淆矩阵上是一个两行两列的交叉矩阵，行分别代表实际的正例和负例，列分别代表预测的正例和负例。</p>
<p><img src="https://raw.githubusercontent.com/TingtingHus/PicBed/main/pics/image.png" alt="混淆矩阵.png"></p>
<p>那么在以上矩阵中：四个象限分别代表四种判别结果：<br>左上角被称为真阳性（True Positive,TP）:样本实际为正（这里的正负仅仅是相对意义上我们想要研究的类别）例，且模型预测结果为正例；<br>右上角被称为假阴性（False Negative，FN）:样本实际为正例，但模型预测为负例；<br>左下角被称为假阳性（False Positive，FP）：样本实际类别为负例，但模型预测为正例；<br>右下角被称为真阴性（True Negative，TN）：样本实际类别为负例，且模型预测为负例。</p>
<p>混淆矩阵的四个象限有明显的规律，左上角至右下角的对角线上是预测正确（以T开头），另一条对角线则预测错误（以F开头），左侧上下象限是预测为真的类别（以P结尾），右侧上下象限为预测错误的类别（以N结尾）</p>
<h2 id="评价指标-1"><a href="#评价指标-1" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="分类准确率（即所有分类中被正确分类的比例，也称识别率）"><a href="#分类准确率（即所有分类中被正确分类的比例，也称识别率）" class="headerlink" title="分类准确率（即所有分类中被正确分类的比例，也称识别率）"></a>分类准确率（即所有分类中被正确分类的比例，也称识别率）</h3><p>(TP + TN)/(TP + TN + FN + FN)</p>
<h3 id="召回率-Recall（也称灵敏率、真正例识别率）"><a href="#召回率-Recall（也称灵敏率、真正例识别率）" class="headerlink" title="召回率-Recall（也称灵敏率、真正例识别率）"></a>召回率-Recall（也称灵敏率、真正例识别率）</h3><p>Recall = TP/(TP + FN)<br>召回率的含义是指：正确识别的正例个数在实际为正例的样本数中的占比</p>
<h3 id="精确率：预测为真的正样本占所有预测为正样本的比例。"><a href="#精确率：预测为真的正样本占所有预测为正样本的比例。" class="headerlink" title="精确率：预测为真的正样本占所有预测为正样本的比例。"></a>精确率：预测为真的正样本占所有预测为正样本的比例。</h3><p>Precision = TP/(TP + FP)</p>
<h3 id="F1-Score（F度量或者F分数）"><a href="#F1-Score（F度量或者F分数）" class="headerlink" title="F1-Score（F度量或者F分数）"></a>F1-Score（F度量或者F分数）</h3><p>F度量 = 2Precision*Recall/(Precision + Recall)<br>F度量是是基于以上度量（精确率和召回率）衍生的计算指标，F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。</p>
<h3 id="Loss-Function-损失函数"><a href="#Loss-Function-损失函数" class="headerlink" title="Loss Function(损失函数)"></a>Loss Function(损失函数)</h3><h2 id="图形评价-1"><a href="#图形评价-1" class="headerlink" title="图形评价"></a>图形评价</h2><h3 id="PR-Precision-Recall-曲线"><a href="#PR-Precision-Recall-曲线" class="headerlink" title="PR(Precision Recall) 曲线"></a>PR(Precision Recall) 曲线</h3><p>由于Precision与Recall之间的制衡关系, 可以利用PR曲线来寻找那个完美制衡点.也就是越靠右上越好.</p>
<p><img src="https://raw.githubusercontent.com/TingtingHus/PicBed/main/pics/1611742935175.jpg" alt="PR曲线.jpg"></p>
<p>举例: 在判断肿瘤是否为良性的诊断中, 我们可能会选择Recall高的模型, 即使会牺牲掉Precision. 宁愿100个里面判断20个为恶性(其中只有10个是正确的), 也不要判断为恶性有7个, 漏了两个.<br>所以面临如何选择的时候, 我们引入ROC曲线.</p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>横坐标是false positive rate(FPR)，纵坐标是true positive rate(TPR)。ROC的全名叫做Receiver Operating Characteristic，主要通过平面坐标系上的曲线来衡量分类模型结果好坏——ROC curve</p>
<p>纵坐标TPR是<strong>真正率</strong>，即是上述的指标召回率，TPR = TP/(TP + FN)<br>横坐标FPR是<strong>假正率</strong>，指代负样本中的错判率，FPR = FP/(FP + TN)</p>
<p>典型的ROC曲线是一个位于坐标点（0,0）和（1,1)对角线上方的曲线，因为对角线代表着随机分类器的分类效果。</p>
<p><img src="https://raw.githubusercontent.com/TingtingHus/PicBed/main/pics/ROC.jpg" alt="ROC曲线.jpg"></p>
<p>ROC曲线和P-R曲线有些类似，ROC曲线越靠近左上角性能越好。左上角坐标为(0, 1)，即FPR=0，TPR=1，根据FPR和TPR公可以得知，此时FN=0， FP=0，模型对所有样本分类正确，绘制ROC曲线很简单，首先对所有样本按预测概率排序，以每条样本的预测概率为阈值，计算相应的FPR和TPR，然后线段连接。</p>
<p>当数据量少时，绘制的ROC曲线不平滑；当数据量大时，绘制的ROC曲线会趋于平滑。理想中的ROC缺陷应该是平滑的, 因为通过提高敏感度, 错误率也应该是随之上升. 如果不够平滑, 有可能是发生了overfitting或者是样本不足.</p>
<h3 id="AUC指标"><a href="#AUC指标" class="headerlink" title="AUC指标"></a>AUC指标</h3><p>当然我们的想法是TPrate越高越好,FPrate越低越好. 显然是不可能的, 因此在ROC的基础上又引入了AUC. 它用来表示ROC曲线下的三角形面积大小，通常，AUC的值介于0.5到1.0之间，较大的AUC代表了较好的performance。</p>
<h1 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h1><h2 id="多分类转化为2vs2问题来评价"><a href="#多分类转化为2vs2问题来评价" class="headerlink" title="多分类转化为2vs2问题来评价"></a>多分类转化为2vs2问题来评价</h2><p>对于多分类问题，或者在二分类问题中，我们有时候会有多组混淆矩阵。<br>例如：多次训练或者在多个数据集上训练的结果，那么估算全局性能的方法有两种，分为宏平均（macro-average）和微平均（micro-average）。简单理解，宏平均就是先算出每个混淆矩阵的P值和R值，然后取得平均P值macro-P和平均R值macro-R，再算出[Math Processing Error]或[Math Processing Error]，而微平均则是计算出混淆矩阵的平均TP、FP、TN、FN，接着进行计算P、R，进而求出[Math Processing Error]或[Math Processing Error]。其它分类指标同理，均可以通过宏平均/微平均计算得出。</p>
<p>准确率：与二分类相同，预测正确的样本占总样本的比例。<br>精确率： ‘macro’， 对于每个标签，分别计算Precision，然后取不加权平均<br>查全率： ‘macro’，对于每个标签，分别计算Recall，然后取不加权平均<br>F1-Score：‘macro’， 对于每个标签，分别计算发，然后取不加权平均<br>‘micro’, 将n个二分类评价的TP,FP,FN对应相加，计算P和R，然后求得F1<br>一般macro-f1和micro-f1都高的分类器性能好</p>
<p>需要注意的是，在多分类任务场景中，如果非要用一个综合考量的metric的话，宏平均会比微平均更好一些，因为宏平均受稀有类别影响更大。宏平均平等对待每一个类别，所以它的值主要受到稀有类别的影响，而微平均平等考虑数据集中的每一个样本，所以它的值受到常见类别的影响比较大。</p>
<h2 id="多分类评价指标"><a href="#多分类评价指标" class="headerlink" title="多分类评价指标"></a>多分类评价指标</h2><h3 id="Kappa系数"><a href="#Kappa系数" class="headerlink" title="Kappa系数"></a>Kappa系数</h3><p>kappa系数是用在统计学中评估一致性的一种方法，取值范围是[-1,1]，实际应用中，一般是[0,1]，与ROC曲线中一般不会出现下凸形曲线的原理类似。这个系数的值越高，则代表模型实现的分类准确度越高。<br>K = (P0-Pe) / (1-Pe)</p>
<p>P0表示总体分类精度<br>Pe表示SUM（第i类真实样本数*第i类预测出来的样本数）/样本总数平方</p>
<h3 id="海明距离"><a href="#海明距离" class="headerlink" title="海明距离"></a>海明距离</h3><h3 id="杰卡德相似系数"><a href="#杰卡德相似系数" class="headerlink" title="杰卡德相似系数"></a>杰卡德相似系数</h3><h3 id="铰链损失"><a href="#铰链损失" class="headerlink" title="铰链损失"></a>铰链损失</h3></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Tingting Hu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2021/01/27/方法总结：怎样评价模型的好坏/">http://example.com/2021/01/27/方法总结：怎样评价模型的好坏/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/01/29/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0%EF%BC%9AB%20testing%20%E6%A6%82%E8%AE%BA/"><i class="fa fa-chevron-left">  </i><span>常用机器学习优缺点</span></a></div><div class="next-post pull-right"><a href="/2021/01/15/%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%EF%BC%9APyEcharts%E5%B8%B8%E7%94%A8%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%84%E4%BB%B6-%E5%87%BD%E6%95%B0%E5%8C%96/"><span>PyEcharts常用可视化组件-函数化</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(/images/top.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2021 By Tingting Hu</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>